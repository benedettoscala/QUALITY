{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leotodisco/QUALITY/blob/main/2_Shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WVmXh8pkpjq"
      },
      "source": [
        "**Import library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmNZqc7lj5T0",
        "outputId": "7d198a9a-72e9-4ddf-ef09-8f7a59b64159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.66.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.4.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.1.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting aif360\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.16.0)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.6.1\n",
            "Requirement already satisfied: aif360[Reductions] in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360[Reductions]) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360[Reductions]) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360[Reductions]) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360[Reductions]) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360[Reductions]) (3.7.1)\n",
            "Collecting fairlearn~=0.7 (from aif360[Reductions])\n",
            "  Downloading fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[Reductions]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[Reductions]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[Reductions]) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360[Reductions]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360[Reductions]) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[Reductions]) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360[Reductions]) (1.16.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.10.0\n",
            "Requirement already satisfied: aif360[inFairness] in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360[inFairness]) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360[inFairness]) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360[inFairness]) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360[inFairness]) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360[inFairness]) (3.7.1)\n",
            "Collecting skorch (from aif360[inFairness])\n",
            "  Downloading skorch-1.0.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inFairness>=0.2.2 (from aif360[inFairness])\n",
            "  Downloading inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting POT>=0.8.0 (from inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading POT-0.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from inFairness>=0.2.2->aif360[inFairness]) (2.3.0+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[inFairness]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[inFairness]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360[inFairness]) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360[inFairness]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360[inFairness]) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360[inFairness]) (3.1.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch->aif360[inFairness]) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch->aif360[inFairness]) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360[inFairness]) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, POT, nvidia-cusparse-cu12, nvidia-cudnn-cu12, skorch, nvidia-cusolver-cu12, inFairness\n",
            "Successfully installed POT-0.9.3 inFairness-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 skorch-1.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install lazypredict\n",
        "%pip install seaborn\n",
        "%pip install matplotlib\n",
        "%pip install aif360\n",
        "%pip install 'aif360[Reductions]'\n",
        "%pip install 'aif360[inFairness]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/leotodisco/QUALITY.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NQgRfXxLTc-",
        "outputId": "be5b2925-1038-425f-d29f-2c0ce417aad5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'QUALITY'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 61 (delta 20), reused 22 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (61/61), 614.27 KiB | 4.52 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/QUALITY\"\n",
        "!git pull\n",
        "\n",
        "%cd ..\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X14vecXOuqA",
        "outputId": "d52102e0-ba18-48df-a015-91fd40ca7441"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/QUALITY\n",
            "Already up to date.\n",
            "/content\n",
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utsnqRrjlT3J"
      },
      "source": [
        "## K-Fold Experiments and Models Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHFdSI5YhQh1"
      },
      "source": [
        "LazyPredict test (without k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qFLpr7ISlMzX",
        "outputId": "78649993-1cf3-4cd9-8cb5-adbe4191027f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 11.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 390, number of negative: 410\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 401\n",
            "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.487500 -> initscore=-0.050010\n",
            "[LightGBM] [Info] Start training from score -0.050010\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "SVC                                0.97               0.97     0.97      0.97   \n",
              "NuSVC                              0.97               0.97     0.97      0.97   \n",
              "LinearSVC                          0.96               0.97     0.97      0.97   \n",
              "CalibratedClassifierCV             0.96               0.97     0.97      0.97   \n",
              "BaggingClassifier                  0.96               0.96     0.96      0.96   \n",
              "SGDClassifier                      0.96               0.96     0.96      0.96   \n",
              "LogisticRegression                 0.96               0.96     0.96      0.96   \n",
              "KNeighborsClassifier               0.96               0.96     0.96      0.96   \n",
              "LinearDiscriminantAnalysis         0.95               0.96     0.96      0.96   \n",
              "RidgeClassifierCV                  0.95               0.96     0.96      0.96   \n",
              "RidgeClassifier                    0.95               0.96     0.96      0.96   \n",
              "AdaBoostClassifier                 0.95               0.96     0.96      0.96   \n",
              "RandomForestClassifier             0.95               0.95     0.95      0.95   \n",
              "DecisionTreeClassifier             0.95               0.95     0.95      0.95   \n",
              "LGBMClassifier                     0.95               0.95     0.95      0.95   \n",
              "ExtraTreesClassifier               0.95               0.95     0.95      0.95   \n",
              "LabelSpreading                     0.95               0.95     0.95      0.95   \n",
              "LabelPropagation                   0.95               0.95     0.95      0.95   \n",
              "ExtraTreeClassifier                0.93               0.93     0.93      0.93   \n",
              "PassiveAggressiveClassifier        0.92               0.92     0.92      0.92   \n",
              "Perceptron                         0.83               0.82     0.82      0.83   \n",
              "BernoulliNB                        0.81               0.80     0.80      0.80   \n",
              "GaussianNB                         0.72               0.70     0.70      0.70   \n",
              "QuadraticDiscriminantAnalysis      0.71               0.69     0.69      0.69   \n",
              "DummyClassifier                    0.46               0.50     0.50      0.29   \n",
              "NearestCentroid                    0.49               0.49     0.49      0.49   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "SVC                                  0.10  \n",
              "NuSVC                                0.09  \n",
              "LinearSVC                            0.12  \n",
              "CalibratedClassifierCV               0.22  \n",
              "BaggingClassifier                    0.07  \n",
              "SGDClassifier                        0.09  \n",
              "LogisticRegression                   0.09  \n",
              "KNeighborsClassifier                 0.05  \n",
              "LinearDiscriminantAnalysis           0.09  \n",
              "RidgeClassifierCV                    0.08  \n",
              "RidgeClassifier                      0.05  \n",
              "AdaBoostClassifier                   0.19  \n",
              "RandomForestClassifier               0.28  \n",
              "DecisionTreeClassifier               0.05  \n",
              "LGBMClassifier                       0.15  \n",
              "ExtraTreesClassifier                 0.19  \n",
              "LabelSpreading                       0.11  \n",
              "LabelPropagation                     0.11  \n",
              "ExtraTreeClassifier                  0.03  \n",
              "PassiveAggressiveClassifier          0.04  \n",
              "Perceptron                           0.04  \n",
              "BernoulliNB                          0.05  \n",
              "GaussianNB                           0.03  \n",
              "QuadraticDiscriminantAnalysis        0.07  \n",
              "DummyClassifier                      0.04  \n",
              "NearestCentroid                      0.09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-536b9d13-e7ea-4b2c-bed5-51d9d97d92d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVC</th>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelSpreading</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelPropagation</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.83</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.81</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.71</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-536b9d13-e7ea-4b2c-bed5-51d9d97d92d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-536b9d13-e7ea-4b2c-bed5-51d9d97d92d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-536b9d13-e7ea-4b2c-bed5-51d9d97d92d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c15a3d3d-1f46-4801-9911-270ad64621b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c15a3d3d-1f46-4801-9911-270ad64621b3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c15a3d3d-1f46-4801-9911-270ad64621b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "models",
              "summary": "{\n  \"name\": \"models\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"LinearDiscriminantAnalysis\",\n          \"LabelSpreading\",\n          \"SVC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14081206788318412,\n        \"min\": 0.46,\n        \"max\": 0.97,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.46,\n          0.72,\n          0.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balanced Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13925332391010461,\n        \"min\": 0.4905394524959742,\n        \"max\": 0.9698067632850241,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.9698067632850241,\n          0.9551127214170693,\n          0.927938808373591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13925332391010461,\n        \"min\": 0.4905394524959743,\n        \"max\": 0.9698067632850241,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.9698067632850241,\n          0.9551127214170693,\n          0.927938808373591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1659235312867818,\n        \"min\": 0.28986301369863016,\n        \"max\": 0.97,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.97,\n          0.9550169704588309,\n          0.9298585858585859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time Taken\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06352850555935857,\n        \"min\": 0.0283355712890625,\n        \"max\": 0.2823598384857178,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          0.09012246131896973,\n          0.1134340763092041,\n          0.10210013389587402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "data_path = \"/content/QUALITY/datasets/2-Shot/terzo_dataset_generato.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "X = df.drop('target',axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B7PAtb8l59D"
      },
      "source": [
        "K-fold (k=10) cross validation, collecting Accuracy and F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F_K62L6El7xc",
        "outputId": "4518670d-5285-4702-a32b-a1d96ecdc6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 452, number of negative: 448\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 399\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502222 -> initscore=0.008889\n",
            "[LightGBM] [Info] Start training from score 0.008889\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 27 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 12.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 452, number of negative: 448\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 401\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502222 -> initscore=0.008889\n",
            "[LightGBM] [Info] Start training from score 0.008889\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 53 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 451, number of negative: 449\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 397\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501111 -> initscore=0.004444\n",
            "[LightGBM] [Info] Start training from score 0.004444\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 79 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:03<00:00,  8.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 444, number of negative: 456\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 399\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493333 -> initscore=-0.026668\n",
            "[LightGBM] [Info] Start training from score -0.026668\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 105 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00,  9.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 457, number of negative: 443\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 400\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507778 -> initscore=0.031114\n",
            "[LightGBM] [Info] Start training from score 0.031114\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 131 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 444, number of negative: 456\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 401\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493333 -> initscore=-0.026668\n",
            "[LightGBM] [Info] Start training from score -0.026668\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 157 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 11.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 443, number of negative: 457\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 398\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492222 -> initscore=-0.031114\n",
            "[LightGBM] [Info] Start training from score -0.031114\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Processing Fold 183 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:05<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 447, number of negative: 453\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 401\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496667 -> initscore=-0.013334\n",
            "[LightGBM] [Info] Start training from score -0.013334\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 29/29 [00:05<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 209 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 28/29 [00:05<00:00, 10.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 445, number of negative: 455\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 398\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494444 -> initscore=-0.022223\n",
            "[LightGBM] [Info] Start training from score -0.022223\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 29/29 [00:05<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 235 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:05<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 447, number of negative: 453\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 399\n",
            "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 48\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496667 -> initscore=-0.013334\n",
            "[LightGBM] [Info] Start training from score -0.013334\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Fold                   Model Accuracy F1-Score\n",
              "0      1      AdaBoostClassifier     0.96     0.96\n",
              "1      2          LGBMClassifier     0.96     0.96\n",
              "2      3      LogisticRegression     0.95     0.95\n",
              "3      4    KNeighborsClassifier     0.95     0.95\n",
              "4      5  DecisionTreeClassifier     0.94     0.94\n",
              "..   ...                     ...      ...      ...\n",
              "265  NaN                     NaN      NaN      NaN\n",
              "266  NaN                     NaN      NaN      NaN\n",
              "267  NaN                     NaN      NaN      NaN\n",
              "268  NaN                     NaN      NaN      NaN\n",
              "269  NaN                     NaN      NaN      NaN\n",
              "\n",
              "[270 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8355badd-215e-4242-a03a-70f0c0168269\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fold</th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8355badd-215e-4242-a03a-70f0c0168269')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8355badd-215e-4242-a03a-70f0c0168269 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8355badd-215e-4242-a03a-70f0c0168269');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acc07541-23db-48f9-af79-c371fc818e11\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acc07541-23db-48f9-af79-c371fc818e11')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acc07541-23db-48f9-af79-c371fc818e11 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 270,\n  \"fields\": [\n    {\n      \"column\": \"Fold\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 260,\n        \"num_unique_values\": 260,\n        \"samples\": [\n          31,\n          182,\n          224\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"SGDClassifier\",\n          \"LabelSpreading\",\n          \"AdaBoostClassifier\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.41,\n        \"max\": 1.0,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.68,\n          0.49,\n          0.92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.238,\n        \"max\": 1.0,\n        \"num_unique_values\": 59,\n        \"samples\": [\n          0.96,\n          0.835,\n          0.629\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "result = pd.DataFrame(columns=[\"Fold\",\"Model\",\"Accuracy\",\"F1-Score\"], index=np.arange(270))\n",
        "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
        "\n",
        "counter = 0\n",
        "foldcounter = 1\n",
        "for train_index, test_index in fold.split(X, y):\n",
        "        print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
        "        X_train, X_test, y_train, y_test = \\\n",
        "            X[ X.index.isin(train_index)], X[ X.index.isin(test_index)], y[train_index], y[test_index]\n",
        "        clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "        models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "        for model in models[:].iterrows():\n",
        "          result.loc[counter][\"Fold\"] = foldcounter\n",
        "          result.loc[counter][\"Model\"] = model[0]\n",
        "          result.loc[counter][\"Accuracy\"] = round(model[1][0],3)\n",
        "          result.loc[counter][\"F1-Score\"] = round(model[1][3],3)\n",
        "          counter += 1\n",
        "          foldcounter += 1\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6fYTqaohlGt",
        "outputId": "34babd73-9664-4816-be66-79ea24103474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model Accuracy\n",
            "25                            SVC     0.96\n",
            "15             LogisticRegression     0.96\n",
            "17                          NuSVC     0.96\n",
            "0              AdaBoostClassifier     0.96\n",
            "23              RidgeClassifierCV     0.96\n",
            "10                 LGBMClassifier     0.96\n",
            "4          DecisionTreeClassifier     0.95\n",
            "3          CalibratedClassifierCV     0.95\n",
            "22                RidgeClassifier     0.95\n",
            "14                      LinearSVC     0.95\n",
            "24                  SGDClassifier     0.95\n",
            "21         RandomForestClassifier     0.95\n",
            "9            KNeighborsClassifier     0.95\n",
            "13     LinearDiscriminantAnalysis     0.95\n",
            "7            ExtraTreesClassifier     0.95\n",
            "11               LabelPropagation     0.95\n",
            "12                 LabelSpreading     0.95\n",
            "6             ExtraTreeClassifier     0.95\n",
            "1               BaggingClassifier     0.94\n",
            "19                     Perceptron     0.94\n",
            "18    PassiveAggressiveClassifier     0.92\n",
            "20  QuadraticDiscriminantAnalysis     0.79\n",
            "8                      GaussianNB     0.68\n",
            "2                     BernoulliNB     0.66\n",
            "16                NearestCentroid     0.58\n",
            "5                 DummyClassifier     0.46\n"
          ]
        }
      ],
      "source": [
        "print(result.groupby('Model', as_index=False)['Accuracy'].mean().sort_values(by='Accuracy', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAq-u8NzhnAo",
        "outputId": "2d811498-373e-488f-d20f-7ee92bbd3357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Model F1-Score\n",
            "25                            SVC     0.96\n",
            "15             LogisticRegression     0.96\n",
            "17                          NuSVC     0.96\n",
            "0              AdaBoostClassifier     0.96\n",
            "23              RidgeClassifierCV     0.96\n",
            "10                 LGBMClassifier     0.96\n",
            "4          DecisionTreeClassifier     0.95\n",
            "3          CalibratedClassifierCV     0.95\n",
            "22                RidgeClassifier     0.95\n",
            "14                      LinearSVC     0.95\n",
            "24                  SGDClassifier     0.95\n",
            "21         RandomForestClassifier     0.95\n",
            "9            KNeighborsClassifier     0.95\n",
            "13     LinearDiscriminantAnalysis     0.95\n",
            "7            ExtraTreesClassifier     0.95\n",
            "11               LabelPropagation     0.95\n",
            "12                 LabelSpreading     0.95\n",
            "6             ExtraTreeClassifier     0.95\n",
            "1               BaggingClassifier     0.94\n",
            "19                     Perceptron     0.94\n",
            "18    PassiveAggressiveClassifier     0.92\n",
            "20  QuadraticDiscriminantAnalysis     0.79\n",
            "2                     BernoulliNB     0.65\n",
            "8                      GaussianNB     0.65\n",
            "16                NearestCentroid     0.58\n",
            "5                 DummyClassifier     0.29\n"
          ]
        }
      ],
      "source": [
        "print(result.groupby('Model', as_index=False)['F1-Score'].mean().sort_values(by='F1-Score', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqRXSAcr4pcx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0J3gLdRjQ3h"
      },
      "source": [
        "The 5 best results are provided by:\n",
        "\n",
        "- **SVC** (Accuracy: 0.96, F1: 0.96)\n",
        "- **LogisticRegression** (Accuracy: 0.96, F1: 0.96)\n",
        "- **NuSVC** (Accuracy: 0.96, F1: 0.96)\n",
        "- **AdaBoostClassifier** (Accuracy: 0.96, F1: 0.96)\n",
        "- **RidgeClassifierCV** (Accuracy: 0.96, F1: 0.96)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCzW2LF0h5vt"
      },
      "source": [
        "# HyperParameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWZiGukwh-Kp"
      },
      "source": [
        "### GridSearchCV - LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLm8FNSGiASa"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(data_path)\n",
        "X = dataset.drop('target',axis=1)\n",
        "y = dataset['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state =42) #test size 0.2 (80/20) e random state 42\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "\n",
        "categorical_features = ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False )\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', one_hot_encoder, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # Lascia le altre colonne inalterate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h81TMtF-iFVk",
        "outputId": "0a703c14-9958-46cb-ac89-a2d1e485be00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape di X_train: (800, 57)\n",
            "Shape di X_test: (200, 57)\n",
            "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
            "[CV 1/10] END class_weight=None; accuracy: (test=0.887) f1: (test=0.892) precision: (test=0.881) recall: (test=0.902) total time=   1.3s\n",
            "[CV 2/10] END class_weight=None; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.6s\n",
            "[CV 3/10] END class_weight=None; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.1s\n",
            "[CV 4/10] END class_weight=None; accuracy: (test=0.762) f1: (test=0.776) precision: (test=0.750) recall: (test=0.805) total time=   0.0s\n",
            "[CV 5/10] END class_weight=None; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.1s\n",
            "[CV 6/10] END class_weight=None; accuracy: (test=0.863) f1: (test=0.874) precision: (test=0.826) recall: (test=0.927) total time=   0.0s\n",
            "[CV 7/10] END class_weight=None; accuracy: (test=0.950) f1: (test=0.953) precision: (test=0.911) recall: (test=1.000) total time=   0.1s\n",
            "[CV 8/10] END class_weight=None; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.0s\n",
            "[CV 9/10] END class_weight=None; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 10/10] END class_weight=None; accuracy: (test=0.875) f1: (test=0.889) precision: (test=0.816) recall: (test=0.976) total time=   0.0s\n",
            "[CV 1/10] END class_weight=balanced; accuracy: (test=0.887) f1: (test=0.892) precision: (test=0.881) recall: (test=0.902) total time=   0.0s\n",
            "[CV 2/10] END class_weight=balanced; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 3/10] END class_weight=balanced; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   0.0s\n",
            "[CV 4/10] END class_weight=balanced; accuracy: (test=0.863) f1: (test=0.867) precision: (test=0.857) recall: (test=0.878) total time=   0.1s\n",
            "[CV 5/10] END class_weight=balanced; accuracy: (test=0.825) f1: (test=0.837) precision: (test=0.800) recall: (test=0.878) total time=   0.0s\n",
            "[CV 6/10] END class_weight=balanced; accuracy: (test=0.875) f1: (test=0.884) precision: (test=0.844) recall: (test=0.927) total time=   0.0s\n",
            "[CV 7/10] END class_weight=balanced; accuracy: (test=0.887) f1: (test=0.889) precision: (test=0.900) recall: (test=0.878) total time=   0.0s\n",
            "[CV 8/10] END class_weight=balanced; accuracy: (test=0.838) f1: (test=0.847) precision: (test=0.818) recall: (test=0.878) total time=   0.0s\n",
            "[CV 9/10] END class_weight=balanced; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.0s\n",
            "[CV 10/10] END class_weight=balanced; accuracy: (test=0.738) f1: (test=0.759) precision: (test=0.717) recall: (test=0.805) total time=   0.0s\n",
            "{'class_weight': None}\n",
            "LogisticRegression(n_jobs=-1, random_state=0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model = LogisticRegression(n_jobs=-1, random_state=0)\n",
        "\n",
        "param_grid = {\n",
        "    #'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    #'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    #'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    #'max_iter': [100, 200, 300, 500, 1000],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "\n",
        "precision_scorer = make_scorer(precision_score, zero_division=0)\n",
        "custom_scoring = {\"accuracy\": \"accuracy\", \"precision\": precision_scorer, \"recall\": \"recall\", \"f1\": \"f1\"}\n",
        "\n",
        "grid_logisticRegression = GridSearchCV(model, param_grid, refit = 'accuracy', verbose = 3, scoring=custom_scoring, cv=10)\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "print(\"Shape di X_train:\", X_train.shape)\n",
        "print(\"Shape di X_test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid_logisticRegression.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid_logisticRegression.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_logisticRegression.best_estimator_)\n",
        "\n",
        "grid_logisticRegression.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGFNGFWPuWYe"
      },
      "source": [
        "## GridSearchCV - NuSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyBE6XJLudNd",
        "outputId": "789c5b4e-7ea3-4d70-e0e1-b6f7160b74c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
            "[CV 1/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.412) f1: (test=0.338) precision: (test=0.400) recall: (test=0.293) total time= 1.3min\n",
            "[CV 2/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.575) f1: (test=0.575) precision: (test=0.590) recall: (test=0.561) total time= 1.3min\n",
            "[CV 3/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.637) f1: (test=0.651) precision: (test=0.643) recall: (test=0.659) total time=  32.4s\n",
            "[CV 4/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.537) f1: (test=0.575) precision: (test=0.543) recall: (test=0.610) total time=  25.7s\n",
            "[CV 5/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.637) f1: (test=0.613) precision: (test=0.676) recall: (test=0.561) total time= 1.2min\n",
            "[CV 6/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.512) f1: (test=0.541) precision: (test=0.523) recall: (test=0.561) total time= 1.2min\n",
            "[CV 7/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.700) f1: (test=0.739) precision: (test=0.667) recall: (test=0.829) total time=  51.3s\n",
            "[CV 8/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.713) f1: (test=0.723) precision: (test=0.714) recall: (test=0.732) total time= 1.2min\n",
            "[CV 9/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.487) f1: (test=0.549) precision: (test=0.500) recall: (test=0.610) total time=  31.1s\n",
            "[CV 10/10] END gamma=scale, kernel=linear, nu=0.1; accuracy: (test=0.600) f1: (test=0.628) precision: (test=0.600) recall: (test=0.659) total time=  35.6s\n",
            "[CV 1/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=  12.5s\n",
            "[CV 2/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=  19.4s\n",
            "[CV 3/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  15.8s\n",
            "[CV 4/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=  10.9s\n",
            "[CV 5/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=  15.6s\n",
            "[CV 6/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=  16.5s\n",
            "[CV 7/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=  10.9s\n",
            "[CV 8/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.1s\n",
            "[CV 9/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   9.8s\n",
            "[CV 10/10] END gamma=scale, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=  23.2s\n",
            "[CV 1/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.562) f1: (test=0.521) precision: (test=0.594) recall: (test=0.463) total time=   0.0s\n",
            "[CV 2/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.562) f1: (test=0.578) precision: (test=0.571) recall: (test=0.585) total time=   0.0s\n",
            "[CV 3/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.537) f1: (test=0.493) precision: (test=0.562) recall: (test=0.439) total time=   0.0s\n",
            "[CV 4/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.575) f1: (test=0.500) precision: (test=0.630) recall: (test=0.415) total time=   0.0s\n",
            "[CV 5/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.588) f1: (test=0.612) precision: (test=0.591) recall: (test=0.634) total time=   0.0s\n",
            "[CV 6/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.400) f1: (test=0.333) precision: (test=0.387) recall: (test=0.293) total time=   0.0s\n",
            "[CV 7/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.500) f1: (test=0.459) precision: (test=0.515) recall: (test=0.415) total time=   0.0s\n",
            "[CV 8/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.487) f1: (test=0.494) precision: (test=0.500) recall: (test=0.488) total time=   0.0s\n",
            "[CV 9/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.425) f1: (test=0.179) precision: (test=0.333) recall: (test=0.122) total time=   0.0s\n",
            "[CV 10/10] END gamma=scale, kernel=linear, nu=0.9; accuracy: (test=0.487) f1: (test=0.438) precision: (test=0.500) recall: (test=0.390) total time=   0.0s\n",
            "[CV 1/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.438) f1: (test=0.416) precision: (test=0.444) recall: (test=0.390) total time=   0.0s\n",
            "[CV 2/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.375) f1: (test=0.324) precision: (test=0.364) recall: (test=0.293) total time=   0.0s\n",
            "[CV 3/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.450) f1: (test=0.463) precision: (test=0.463) recall: (test=0.463) total time=   0.0s\n",
            "[CV 4/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.375) f1: (test=0.375) precision: (test=0.385) recall: (test=0.366) total time=   0.0s\n",
            "[CV 5/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.275) f1: (test=0.408) precision: (test=0.351) recall: (test=0.488) total time=   0.0s\n",
            "[CV 6/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.625) f1: (test=0.423) precision: (test=1.000) recall: (test=0.268) total time=   0.0s\n",
            "[CV 7/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.350) f1: (test=0.350) precision: (test=0.359) recall: (test=0.341) total time=   0.0s\n",
            "[CV 8/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.425) f1: (test=0.395) precision: (test=0.429) recall: (test=0.366) total time=   0.0s\n",
            "[CV 9/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.388) f1: (test=0.437) precision: (test=0.413) recall: (test=0.463) total time=   0.0s\n",
            "[CV 10/10] END gamma=scale, kernel=rbf, nu=0.1; accuracy: (test=0.362) f1: (test=0.354) precision: (test=0.368) recall: (test=0.341) total time=   0.0s\n",
            "[CV 1/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.688) f1: (test=0.576) precision: (test=0.944) recall: (test=0.415) total time=   0.1s\n",
            "[CV 2/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.725) f1: (test=0.738) precision: (test=0.721) recall: (test=0.756) total time=   0.1s\n",
            "[CV 3/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.700) f1: (test=0.733) precision: (test=0.673) recall: (test=0.805) total time=   0.1s\n",
            "[CV 4/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.700) f1: (test=0.684) precision: (test=0.743) recall: (test=0.634) total time=   0.1s\n",
            "[CV 5/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.700) f1: (test=0.684) precision: (test=0.743) recall: (test=0.634) total time=   0.1s\n",
            "[CV 6/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.738) f1: (test=0.720) precision: (test=0.794) recall: (test=0.659) total time=   0.0s\n",
            "[CV 7/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.625) f1: (test=0.559) precision: (test=0.704) recall: (test=0.463) total time=   0.0s\n",
            "[CV 8/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.738) f1: (test=0.779) precision: (test=0.685) recall: (test=0.902) total time=   0.0s\n",
            "[CV 9/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.700) f1: (test=0.676) precision: (test=0.758) recall: (test=0.610) total time=   0.1s\n",
            "[CV 10/10] END gamma=scale, kernel=rbf, nu=0.5; accuracy: (test=0.825) f1: (test=0.837) precision: (test=0.800) recall: (test=0.878) total time=   0.1s\n",
            "[CV 1/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.688) f1: (test=0.742) precision: (test=0.643) recall: (test=0.878) total time=   0.0s\n",
            "[CV 2/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.650) f1: (test=0.725) precision: (test=0.607) recall: (test=0.902) total time=   0.0s\n",
            "[CV 3/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.637) f1: (test=0.724) precision: (test=0.594) recall: (test=0.927) total time=   0.0s\n",
            "[CV 4/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.688) f1: (test=0.742) precision: (test=0.643) recall: (test=0.878) total time=   0.0s\n",
            "[CV 5/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.600) f1: (test=0.704) precision: (test=0.567) recall: (test=0.927) total time=   0.0s\n",
            "[CV 6/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.500) f1: (test=0.592) precision: (test=0.509) recall: (test=0.707) total time=   0.0s\n",
            "[CV 7/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.675) f1: (test=0.745) precision: (test=0.623) recall: (test=0.927) total time=   0.0s\n",
            "[CV 8/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.625) f1: (test=0.727) precision: (test=0.580) recall: (test=0.976) total time=   0.0s\n",
            "[CV 9/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.713) f1: (test=0.747) precision: (test=0.680) recall: (test=0.829) total time=   0.0s\n",
            "[CV 10/10] END gamma=scale, kernel=rbf, nu=0.9; accuracy: (test=0.662) f1: (test=0.733) precision: (test=0.617) recall: (test=0.902) total time=   0.0s\n",
            "[CV 1/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.412) f1: (test=0.338) precision: (test=0.400) recall: (test=0.293) total time= 1.1min\n",
            "[CV 2/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.575) f1: (test=0.575) precision: (test=0.590) recall: (test=0.561) total time= 1.2min\n",
            "[CV 3/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.637) f1: (test=0.651) precision: (test=0.643) recall: (test=0.659) total time=  31.6s\n",
            "[CV 4/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.537) f1: (test=0.575) precision: (test=0.543) recall: (test=0.610) total time=  24.7s\n",
            "[CV 5/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.637) f1: (test=0.613) precision: (test=0.676) recall: (test=0.561) total time= 1.2min\n",
            "[CV 6/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.512) f1: (test=0.541) precision: (test=0.523) recall: (test=0.561) total time= 1.2min\n",
            "[CV 7/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.700) f1: (test=0.739) precision: (test=0.667) recall: (test=0.829) total time=  51.6s\n",
            "[CV 8/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.713) f1: (test=0.723) precision: (test=0.714) recall: (test=0.732) total time= 1.2min\n",
            "[CV 9/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.487) f1: (test=0.549) precision: (test=0.500) recall: (test=0.610) total time=  31.8s\n",
            "[CV 10/10] END gamma=auto, kernel=linear, nu=0.1; accuracy: (test=0.600) f1: (test=0.628) precision: (test=0.600) recall: (test=0.659) total time=  34.9s\n",
            "[CV 1/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=  12.5s\n",
            "[CV 2/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=  19.2s\n",
            "[CV 3/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.0s\n",
            "[CV 4/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=  10.6s\n",
            "[CV 5/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=  15.6s\n",
            "[CV 6/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=  16.8s\n",
            "[CV 7/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=  10.6s\n",
            "[CV 8/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.2s\n",
            "[CV 9/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=  10.1s\n",
            "[CV 10/10] END gamma=auto, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=  23.2s\n",
            "[CV 1/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.562) f1: (test=0.521) precision: (test=0.594) recall: (test=0.463) total time=   0.0s\n",
            "[CV 2/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.562) f1: (test=0.578) precision: (test=0.571) recall: (test=0.585) total time=   0.0s\n",
            "[CV 3/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.537) f1: (test=0.493) precision: (test=0.562) recall: (test=0.439) total time=   0.0s\n",
            "[CV 4/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.575) f1: (test=0.500) precision: (test=0.630) recall: (test=0.415) total time=   0.0s\n",
            "[CV 5/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.588) f1: (test=0.612) precision: (test=0.591) recall: (test=0.634) total time=   0.0s\n",
            "[CV 6/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.400) f1: (test=0.333) precision: (test=0.387) recall: (test=0.293) total time=   0.0s\n",
            "[CV 7/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.500) f1: (test=0.459) precision: (test=0.515) recall: (test=0.415) total time=   0.0s\n",
            "[CV 8/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.487) f1: (test=0.494) precision: (test=0.500) recall: (test=0.488) total time=   0.0s\n",
            "[CV 9/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.425) f1: (test=0.179) precision: (test=0.333) recall: (test=0.122) total time=   0.0s\n",
            "[CV 10/10] END gamma=auto, kernel=linear, nu=0.9; accuracy: (test=0.487) f1: (test=0.438) precision: (test=0.500) recall: (test=0.390) total time=   0.0s\n",
            "[CV 1/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.887) f1: (test=0.883) precision: (test=0.944) recall: (test=0.829) total time=   0.0s\n",
            "[CV 2/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.0s\n",
            "[CV 3/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.912) f1: (test=0.909) precision: (test=0.972) recall: (test=0.854) total time=   0.0s\n",
            "[CV 4/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.887) f1: (test=0.889) precision: (test=0.900) recall: (test=0.878) total time=   0.0s\n",
            "[CV 5/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   0.0s\n",
            "[CV 6/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.912) f1: (test=0.909) precision: (test=0.972) recall: (test=0.854) total time=   0.0s\n",
            "[CV 7/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.1s\n",
            "[CV 8/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.0s\n",
            "[CV 9/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 10/10] END gamma=auto, kernel=rbf, nu=0.1; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.0s\n",
            "[CV 1/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.887) f1: (test=0.883) precision: (test=0.944) recall: (test=0.829) total time=   0.1s\n",
            "[CV 2/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 3/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.875) f1: (test=0.868) precision: (test=0.943) recall: (test=0.805) total time=   0.0s\n",
            "[CV 4/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.863) f1: (test=0.857) precision: (test=0.917) recall: (test=0.805) total time=   0.0s\n",
            "[CV 5/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.850) f1: (test=0.838) precision: (test=0.939) recall: (test=0.756) total time=   0.0s\n",
            "[CV 6/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.863) f1: (test=0.849) precision: (test=0.969) recall: (test=0.756) total time=   0.0s\n",
            "[CV 7/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.0s\n",
            "[CV 8/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.0s\n",
            "[CV 9/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.950) f1: (test=0.949) precision: (test=1.000) recall: (test=0.902) total time=   0.0s\n",
            "[CV 10/10] END gamma=auto, kernel=rbf, nu=0.5; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.0s\n",
            "[CV 1/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.887) f1: (test=0.880) precision: (test=0.971) recall: (test=0.805) total time=   0.0s\n",
            "[CV 2/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 3/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.850) f1: (test=0.838) precision: (test=0.939) recall: (test=0.756) total time=   0.1s\n",
            "[CV 4/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.863) f1: (test=0.857) precision: (test=0.917) recall: (test=0.805) total time=   0.0s\n",
            "[CV 5/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.838) f1: (test=0.827) precision: (test=0.912) recall: (test=0.756) total time=   0.1s\n",
            "[CV 6/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.875) f1: (test=0.865) precision: (test=0.970) recall: (test=0.780) total time=   0.1s\n",
            "[CV 7/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.0s\n",
            "[CV 8/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.0s\n",
            "[CV 9/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.887) f1: (test=0.877) precision: (test=1.000) recall: (test=0.780) total time=   0.0s\n",
            "[CV 10/10] END gamma=auto, kernel=rbf, nu=0.9; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.1s\n",
            "[CV 1/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.412) f1: (test=0.338) precision: (test=0.400) recall: (test=0.293) total time= 1.1min\n",
            "[CV 2/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.575) f1: (test=0.575) precision: (test=0.590) recall: (test=0.561) total time= 1.2min\n",
            "[CV 3/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.637) f1: (test=0.651) precision: (test=0.643) recall: (test=0.659) total time=  31.5s\n",
            "[CV 4/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.537) f1: (test=0.575) precision: (test=0.543) recall: (test=0.610) total time=  24.5s\n",
            "[CV 5/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.637) f1: (test=0.613) precision: (test=0.676) recall: (test=0.561) total time= 1.2min\n",
            "[CV 6/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.512) f1: (test=0.541) precision: (test=0.523) recall: (test=0.561) total time= 1.2min\n",
            "[CV 7/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.700) f1: (test=0.739) precision: (test=0.667) recall: (test=0.829) total time=  51.4s\n",
            "[CV 8/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.713) f1: (test=0.723) precision: (test=0.714) recall: (test=0.732) total time= 1.2min\n",
            "[CV 9/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.487) f1: (test=0.549) precision: (test=0.500) recall: (test=0.610) total time=  31.6s\n",
            "[CV 10/10] END gamma=0.1, kernel=linear, nu=0.1; accuracy: (test=0.600) f1: (test=0.628) precision: (test=0.600) recall: (test=0.659) total time=  35.0s\n",
            "[CV 1/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=  12.5s\n",
            "[CV 2/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=  19.4s\n",
            "[CV 3/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.3s\n",
            "[CV 4/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=  10.4s\n",
            "[CV 5/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=  15.6s\n",
            "[CV 6/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=  17.0s\n",
            "[CV 7/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=  10.5s\n",
            "[CV 8/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.1s\n",
            "[CV 9/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   9.8s\n",
            "[CV 10/10] END gamma=0.1, kernel=linear, nu=0.5; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=  23.4s\n",
            "[CV 1/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.562) f1: (test=0.521) precision: (test=0.594) recall: (test=0.463) total time=   0.0s\n",
            "[CV 2/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.562) f1: (test=0.578) precision: (test=0.571) recall: (test=0.585) total time=   0.0s\n",
            "[CV 3/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.537) f1: (test=0.493) precision: (test=0.562) recall: (test=0.439) total time=   0.0s\n",
            "[CV 4/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.575) f1: (test=0.500) precision: (test=0.630) recall: (test=0.415) total time=   0.0s\n",
            "[CV 5/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.588) f1: (test=0.612) precision: (test=0.591) recall: (test=0.634) total time=   0.0s\n",
            "[CV 6/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.400) f1: (test=0.333) precision: (test=0.387) recall: (test=0.293) total time=   0.0s\n",
            "[CV 7/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.500) f1: (test=0.459) precision: (test=0.515) recall: (test=0.415) total time=   0.0s\n",
            "[CV 8/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.487) f1: (test=0.494) precision: (test=0.500) recall: (test=0.488) total time=   0.0s\n",
            "[CV 9/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.425) f1: (test=0.179) precision: (test=0.333) recall: (test=0.122) total time=   0.0s\n",
            "[CV 10/10] END gamma=0.1, kernel=linear, nu=0.9; accuracy: (test=0.487) f1: (test=0.438) precision: (test=0.500) recall: (test=0.390) total time=   0.0s\n",
            "[CV 1/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.863) f1: (test=0.853) precision: (test=0.941) recall: (test=0.780) total time=   0.0s\n",
            "[CV 2/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.1s\n",
            "[CV 3/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.863) f1: (test=0.849) precision: (test=0.969) recall: (test=0.756) total time=   0.1s\n",
            "[CV 4/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.900) f1: (test=0.900) precision: (test=0.923) recall: (test=0.878) total time=   0.0s\n",
            "[CV 5/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.912) f1: (test=0.907) precision: (test=1.000) recall: (test=0.829) total time=   0.0s\n",
            "[CV 6/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.875) f1: (test=0.865) precision: (test=0.970) recall: (test=0.780) total time=   0.0s\n",
            "[CV 7/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 8/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 9/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.912) f1: (test=0.907) precision: (test=1.000) recall: (test=0.829) total time=   0.0s\n",
            "[CV 10/10] END gamma=0.1, kernel=rbf, nu=0.1; accuracy: (test=0.887) f1: (test=0.880) precision: (test=0.971) recall: (test=0.805) total time=   0.0s\n",
            "[CV 1/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.850) f1: (test=0.842) precision: (test=0.914) recall: (test=0.780) total time=   0.1s\n",
            "[CV 2/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.1s\n",
            "[CV 3/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.838) f1: (test=0.817) precision: (test=0.967) recall: (test=0.707) total time=   0.1s\n",
            "[CV 4/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.900) f1: (test=0.900) precision: (test=0.923) recall: (test=0.878) total time=   0.1s\n",
            "[CV 5/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.875) f1: (test=0.861) precision: (test=1.000) recall: (test=0.756) total time=   0.0s\n",
            "[CV 6/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.875) f1: (test=0.865) precision: (test=0.970) recall: (test=0.780) total time=   0.0s\n",
            "[CV 7/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.1s\n",
            "[CV 8/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.0s\n",
            "[CV 9/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.900) f1: (test=0.892) precision: (test=1.000) recall: (test=0.805) total time=   0.0s\n",
            "[CV 10/10] END gamma=0.1, kernel=rbf, nu=0.5; accuracy: (test=0.875) f1: (test=0.868) precision: (test=0.943) recall: (test=0.805) total time=   0.1s\n",
            "[CV 1/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.838) f1: (test=0.812) precision: (test=1.000) recall: (test=0.683) total time=   0.0s\n",
            "[CV 2/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.1s\n",
            "[CV 3/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.838) f1: (test=0.817) precision: (test=0.967) recall: (test=0.707) total time=   0.1s\n",
            "[CV 4/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.875) f1: (test=0.865) precision: (test=0.970) recall: (test=0.780) total time=   0.1s\n",
            "[CV 5/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.838) f1: (test=0.817) precision: (test=0.967) recall: (test=0.707) total time=   0.0s\n",
            "[CV 6/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.887) f1: (test=0.877) precision: (test=1.000) recall: (test=0.780) total time=   0.1s\n",
            "[CV 7/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.0s\n",
            "[CV 8/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   0.0s\n",
            "[CV 9/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.887) f1: (test=0.877) precision: (test=1.000) recall: (test=0.780) total time=   0.0s\n",
            "[CV 10/10] END gamma=0.1, kernel=rbf, nu=0.9; accuracy: (test=0.875) f1: (test=0.868) precision: (test=0.943) recall: (test=0.805) total time=   0.0s\n",
            "{'gamma': 'scale', 'kernel': 'linear', 'nu': 0.5}\n",
            "NuSVC(kernel='linear')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.955"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from sklearn.svm import NuSVC\n",
        "\n",
        "model = NuSVC()\n",
        "# mettere qui gli stessi param del dataset originale\n",
        "param_grid = {\n",
        "    'nu': [0.1, 0.5, 0.9],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto', 0.1],\n",
        "}\n",
        "\n",
        "\n",
        "precision_scorer = make_scorer(precision_score, zero_division=0)\n",
        "custom_scoring = {\"accuracy\": \"accuracy\", \"precision\": precision_scorer, \"recall\": \"recall\", \"f1\": \"f1\"}\n",
        "\n",
        "grid_svc = GridSearchCV(model, param_grid, refit = 'accuracy', verbose = 3, scoring=custom_scoring, cv=10)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid_svc.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid_svc.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_svc.best_estimator_)\n",
        "\n",
        "grid_svc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFKYxkjyRoX"
      },
      "source": [
        "## AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1jjUdCoyW5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86ac0cf-40f2-4b41-f7fc-727c13d731a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 45 candidates, totalling 450 fits\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.725) f1: (test=0.784) precision: (test=0.656) recall: (test=0.976) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.700) f1: (test=0.774) precision: (test=0.631) recall: (test=1.000) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.662) f1: (test=0.748) precision: (test=0.606) recall: (test=0.976) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.725) f1: (test=0.780) precision: (test=0.661) recall: (test=0.951) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.637) f1: (test=0.739) precision: (test=0.586) recall: (test=1.000) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.625) f1: (test=0.722) precision: (test=0.582) recall: (test=0.951) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.713) f1: (test=0.781) precision: (test=0.641) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.625) f1: (test=0.732) precision: (test=0.577) recall: (test=1.000) total time=   0.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.800) f1: (test=0.771) precision: (test=0.931) recall: (test=0.659) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; accuracy: (test=0.700) f1: (test=0.769) precision: (test=0.635) recall: (test=0.976) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.8s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.8s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.8s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.900) f1: (test=0.902) precision: (test=0.902) recall: (test=0.902) total time=   1.7s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   1.2s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.2s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   1.2s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.1s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.2s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   1.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   1.2s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.7s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.4s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.4s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.4s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.4s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.4s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.2s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.2s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   0.4s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   1.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   1.1s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   1.2s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.930) precision: (test=0.889) recall: (test=0.976) total time=   1.4s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.9s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.949) precision: (test=1.000) recall: (test=0.902) total time=   1.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.1s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.1s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   0.2s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   0.2s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.2s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.935) precision: (test=1.000) recall: (test=0.878) total time=   0.8s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.8s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.8s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.8s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.7s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   1.2s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   1.2s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   1.2s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   1.1s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.2s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   1.1s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.1s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.4s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.7s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.4s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.2s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   0.2s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.2s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.949) precision: (test=1.000) recall: (test=0.902) total time=   0.2s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.2s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.2s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   0.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.5s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.2s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   1.2s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   1.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   1.9s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.935) precision: (test=1.000) recall: (test=0.878) total time=   1.2s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.1s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.2s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.1s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.787) f1: (test=0.754) precision: (test=0.929) recall: (test=0.634) total time=   0.2s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.938) f1: (test=0.935) precision: (test=1.000) recall: (test=0.878) total time=   0.2s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.912) f1: (test=0.907) precision: (test=1.000) recall: (test=0.829) total time=   0.2s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.900) f1: (test=0.895) precision: (test=0.971) recall: (test=0.829) total time=   0.2s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.863) f1: (test=0.845) precision: (test=1.000) recall: (test=0.732) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.838) f1: (test=0.822) precision: (test=0.938) recall: (test=0.732) total time=   0.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.812) f1: (test=0.789) precision: (test=0.933) recall: (test=0.683) total time=   0.2s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100; accuracy: (test=0.787) f1: (test=0.746) precision: (test=0.962) recall: (test=0.610) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.787) f1: (test=0.754) precision: (test=0.929) recall: (test=0.634) total time=   0.4s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.935) precision: (test=1.000) recall: (test=0.878) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.912) f1: (test=0.907) precision: (test=1.000) recall: (test=0.829) total time=   0.6s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   0.8s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.900) f1: (test=0.895) precision: (test=0.971) recall: (test=0.829) total time=   0.8s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.863) f1: (test=0.845) precision: (test=1.000) recall: (test=0.732) total time=   0.8s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.838) f1: (test=0.822) precision: (test=0.938) recall: (test=0.732) total time=   0.8s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.812) f1: (test=0.789) precision: (test=0.933) recall: (test=0.683) total time=   0.7s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200; accuracy: (test=0.787) f1: (test=0.746) precision: (test=0.962) recall: (test=0.610) total time=   0.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.787) f1: (test=0.754) precision: (test=0.929) recall: (test=0.634) total time=   1.2s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.938) f1: (test=0.935) precision: (test=1.000) recall: (test=0.878) total time=   1.2s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.912) f1: (test=0.907) precision: (test=1.000) recall: (test=0.829) total time=   1.2s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   1.2s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.900) f1: (test=0.895) precision: (test=0.971) recall: (test=0.829) total time=   1.2s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.863) f1: (test=0.845) precision: (test=1.000) recall: (test=0.732) total time=   1.1s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.838) f1: (test=0.822) precision: (test=0.938) recall: (test=0.732) total time=   1.2s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.812) f1: (test=0.789) precision: (test=0.933) recall: (test=0.683) total time=   1.4s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   1.9s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=500; accuracy: (test=0.787) f1: (test=0.746) precision: (test=0.962) recall: (test=0.610) total time=   1.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.900) f1: (test=0.900) precision: (test=0.923) recall: (test=0.878) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.900) f1: (test=0.900) precision: (test=0.923) recall: (test=0.878) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.6s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.6s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.5s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   1.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   2.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.7s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   1.4s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.4s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   1.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   1.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   1.4s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   1.7s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.4s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.5s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   1.4s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   1.4s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.8s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   2.2s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   1.4s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   1.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   1.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   1.4s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.9s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.8s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   0.9s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.6s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.6s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   1.4s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   1.4s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   1.4s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   1.4s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.7s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   2.1s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.4s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   1.4s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.8s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.8s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.9s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.0s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.7s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   1.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   1.4s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   1.4s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.4s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   1.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   2.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   1.7s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   1.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.588) f1: (test=0.548) precision: (test=0.625) recall: (test=0.488) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.850) f1: (test=0.857) precision: (test=0.837) recall: (test=0.878) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.588) f1: (test=0.548) precision: (test=0.625) recall: (test=0.488) total time=   0.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.6s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.7s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.588) f1: (test=0.548) precision: (test=0.625) recall: (test=0.488) total time=   2.2s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   1.9s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   1.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.912) f1: (test=0.916) precision: (test=0.905) recall: (test=0.927) total time=   1.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   1.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.4s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   1.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   2.0s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.900) f1: (test=0.900) precision: (test=0.923) recall: (test=0.878) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.6s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.4s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.4s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   0.7s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.6s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.6s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.6s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.6s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.6s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   2.6s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   2.1s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   1.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.5s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   1.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.5s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   2.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   0.6s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.953) precision: (test=0.911) recall: (test=1.000) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   0.6s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.6s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.6s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.6s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   2.4s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   2.9s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   3.8s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   3.8s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   4.1s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.9s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   1.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   1.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   1.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   0.7s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   1.0s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   1.0s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.1s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.8s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.6s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.963) f1: (test=0.962) precision: (test=1.000) recall: (test=0.927) total time=   1.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   1.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   1.6s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.9s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   2.6s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   1.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   1.5s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=100; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.4s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=1.000) recall: (test=0.976) total time=   0.9s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.9s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   1.0s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.0s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.6s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   0.6s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=   1.6s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   1.5s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   1.4s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.9s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   2.5s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.7s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=1.000) f1: (test=1.000) precision: (test=1.000) recall: (test=1.000) total time=   1.6s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   1.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.5, n_estimators=500; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   1.5s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   0.3s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.900) f1: (test=0.895) precision: (test=0.971) recall: (test=0.829) total time=   0.3s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.3s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.3s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.912) f1: (test=0.911) precision: (test=0.947) recall: (test=0.878) total time=   0.3s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   0.3s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.938) f1: (test=0.943) precision: (test=0.891) recall: (test=1.000) total time=   0.3s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.3s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=100; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.6s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.900) f1: (test=0.895) precision: (test=0.971) recall: (test=0.829) total time=   0.8s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.9s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   1.0s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   1.0s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.925) f1: (test=0.923) precision: (test=0.973) recall: (test=0.878) total time=   0.9s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.7s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.925) f1: (test=0.932) precision: (test=0.872) recall: (test=1.000) total time=   0.7s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=200; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.6s\n",
            "[CV 1/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.900) f1: (test=0.897) precision: (test=0.946) recall: (test=0.854) total time=   1.5s\n",
            "[CV 2/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.850) f1: (test=0.833) precision: (test=0.968) recall: (test=0.732) total time=   1.5s\n",
            "[CV 3/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   1.4s\n",
            "[CV 4/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   1.5s\n",
            "[CV 5/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.8s\n",
            "[CV 6/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.950) f1: (test=0.949) precision: (test=1.000) recall: (test=0.902) total time=   2.4s\n",
            "[CV 7/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   1.9s\n",
            "[CV 8/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.963) f1: (test=0.965) precision: (test=0.932) recall: (test=1.000) total time=   1.5s\n",
            "[CV 9/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.925) f1: (test=0.929) precision: (test=0.907) recall: (test=0.951) total time=   1.4s\n",
            "[CV 10/10] END base_estimator=DecisionTreeClassifier(max_depth=3), learning_rate=2, n_estimators=500; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   1.5s\n",
            "{'base_estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1.5, 'n_estimators': 100}\n",
            "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
            "                   learning_rate=1.5, n_estimators=100)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.955"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.svm import NuSVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "ada_model = AdaBoostClassifier()\n",
        "\n",
        "# Definisci la griglia di iperparametri\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'learning_rate': [0.01, 0.5, 1, 1.5, 2],\n",
        "    'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)]\n",
        "}\n",
        "\n",
        "precision_scorer = make_scorer(precision_score, zero_division=0)\n",
        "custom_scoring = {\"accuracy\": \"accuracy\", \"precision\": precision_scorer, \"recall\": \"recall\", \"f1\": \"f1\"}\n",
        "\n",
        "grid_ada_boost = GridSearchCV(ada_model, param_grid, refit = 'accuracy', verbose = 3, scoring=custom_scoring, cv=10)\n",
        "\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid_ada_boost.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid_ada_boost.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_ada_boost.best_estimator_)\n",
        "\n",
        "grid_ada_boost.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_g9tRfS0hHG"
      },
      "source": [
        "## GridSearchCV - RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTWF33HQ0ex7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f305f4-821c-4f8c-eaf7-3b30f70eeb03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.1s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.1s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.1s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.1s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.1s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=True; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.2s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.1s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.2s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.2s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.2s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.2s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.2s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=3, fit_intercept=False; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.1s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.3s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.2s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.3s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.3s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.3s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.2s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.950) f1: (test=0.952) precision: (test=0.930) recall: (test=0.976) total time=   0.3s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.3s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.2s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.2s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.2s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.2s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.3s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.5s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=5, fit_intercept=False; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.6s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.9s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.7s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.9s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.9s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.5s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.5s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=True; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.5s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.5s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.4s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.4s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.5s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.4s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.4s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=None, cv=10, fit_intercept=False; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.4s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.1s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.2s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.2s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.950) f1: (test=0.950) precision: (test=0.974) recall: (test=0.927) total time=   0.2s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.2s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.2s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.1s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.1s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.1s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.2s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.1s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.1s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.1s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=3, fit_intercept=False; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.2s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.4s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.6s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.6s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.6s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.6s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.3s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=   0.2s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.2s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.2s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.2s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.2s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.2s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.941) precision: (test=0.909) recall: (test=0.976) total time=   0.2s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=5, fit_intercept=False; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=   0.2s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.925) f1: (test=0.925) precision: (test=0.949) recall: (test=0.902) total time=   0.5s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.953) recall: (test=1.000) total time=   0.5s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=   0.4s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.5s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.5s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=   0.5s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.4s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.4s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=True; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   0.5s\n",
            "[CV 1/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.4s\n",
            "[CV 2/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 3/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.937) precision: (test=0.974) recall: (test=0.902) total time=   0.4s\n",
            "[CV 4/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.4s\n",
            "[CV 5/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 6/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.950) f1: (test=0.951) precision: (test=0.951) recall: (test=0.951) total time=   0.4s\n",
            "[CV 7/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=   0.4s\n",
            "[CV 8/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.975) f1: (test=0.976) precision: (test=0.976) recall: (test=0.976) total time=   0.6s\n",
            "[CV 9/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.938) f1: (test=0.940) precision: (test=0.929) recall: (test=0.951) total time=   0.8s\n",
            "[CV 10/10] END alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], class_weight=balanced, cv=10, fit_intercept=False; accuracy: (test=0.912) f1: (test=0.914) precision: (test=0.925) recall: (test=0.902) total time=   1.0s\n",
            "{'alphas': [0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], 'class_weight': None, 'cv': 3, 'fit_intercept': True}\n",
            "RidgeClassifierCV(alphas=[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0], cv=3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "\n",
        "model = RidgeClassifierCV()\n",
        "\n",
        "param_grid = {\n",
        "    'alphas': [[0.1, 1.0, 10.0, 100.0, 200.0, 500.0, 1000.0]],\n",
        "    'fit_intercept': [True, False],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'cv': [3, 5, 10]\n",
        "}\n",
        "\n",
        "precision_scorer = make_scorer(precision_score, zero_division=0)\n",
        "custom_scoring = {\"accuracy\": \"accuracy\", \"precision\": precision_scorer, \"recall\": \"recall\", \"f1\": \"f1\"}\n",
        "\n",
        "grid_ridge = GridSearchCV(model, param_grid, refit = 'accuracy', verbose = 3, scoring=custom_scoring, cv=10)\n",
        "\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid_ridge.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid_ridge.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_ridge.best_estimator_)\n",
        "\n",
        "grid_ridge.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j6YbL6-4r9Z"
      },
      "source": [
        "## GridSearchCV - SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9ri_ez44wpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d66187-7a60-4168-b91a-49801b152b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 280 candidates, totalling 2800 fits\n",
            "[CV 1/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=  15.2s\n",
            "[CV 2/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  17.0s\n",
            "[CV 3/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  17.7s\n",
            "[CV 4/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=  20.3s\n",
            "[CV 5/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=  20.9s\n",
            "[CV 6/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=  20.6s\n",
            "[CV 7/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.5s\n",
            "[CV 8/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  20.0s\n",
            "[CV 9/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=  15.7s\n",
            "[CV 10/10] END C=0.1, class_weight=None, gamma=scale, kernel=linear; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=  16.5s\n",
            "[CV 1/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.562) f1: (test=0.598) precision: (test=0.565) recall: (test=0.634) total time=   0.0s\n",
            "[CV 2/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.487) f1: (test=0.539) precision: (test=0.500) recall: (test=0.585) total time=   0.0s\n",
            "[CV 3/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.450) f1: (test=0.511) precision: (test=0.469) recall: (test=0.561) total time=   0.0s\n",
            "[CV 4/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.550) f1: (test=0.561) precision: (test=0.561) recall: (test=0.561) total time=   0.0s\n",
            "[CV 5/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.525) f1: (test=0.627) precision: (test=0.525) recall: (test=0.780) total time=   0.0s\n",
            "[CV 6/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.350) f1: (test=0.395) precision: (test=0.378) recall: (test=0.415) total time=   0.0s\n",
            "[CV 7/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.537) f1: (test=0.593) precision: (test=0.540) recall: (test=0.659) total time=   0.0s\n",
            "[CV 8/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.500) f1: (test=0.600) precision: (test=0.508) recall: (test=0.732) total time=   0.0s\n",
            "[CV 9/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.575) f1: (test=0.575) precision: (test=0.590) recall: (test=0.561) total time=   0.0s\n",
            "[CV 10/10] END C=0.1, class_weight=None, gamma=scale, kernel=poly; accuracy: (test=0.537) f1: (test=0.593) precision: (test=0.540) recall: (test=0.659) total time=   0.0s\n",
            "[CV 1/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.562) f1: (test=0.598) precision: (test=0.565) recall: (test=0.634) total time=   0.0s\n",
            "[CV 2/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.500) f1: (test=0.545) precision: (test=0.511) recall: (test=0.585) total time=   0.0s\n",
            "[CV 3/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.450) f1: (test=0.511) precision: (test=0.469) recall: (test=0.561) total time=   0.0s\n",
            "[CV 4/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.537) f1: (test=0.543) precision: (test=0.550) recall: (test=0.537) total time=   0.1s\n",
            "[CV 5/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.525) f1: (test=0.627) precision: (test=0.525) recall: (test=0.780) total time=   0.0s\n",
            "[CV 6/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.350) f1: (test=0.395) precision: (test=0.378) recall: (test=0.415) total time=   0.0s\n",
            "[CV 7/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.537) f1: (test=0.593) precision: (test=0.540) recall: (test=0.659) total time=   0.0s\n",
            "[CV 8/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.500) f1: (test=0.600) precision: (test=0.508) recall: (test=0.732) total time=   0.0s\n",
            "[CV 9/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.588) f1: (test=0.582) precision: (test=0.605) recall: (test=0.561) total time=   0.0s\n",
            "[CV 10/10] END C=0.1, class_weight=None, gamma=scale, kernel=rbf; accuracy: (test=0.537) f1: (test=0.593) precision: (test=0.540) recall: (test=0.659) total time=   0.0s\n",
            "[CV 1/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 2/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 3/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 4/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 5/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 6/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 7/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 8/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 9/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 10/10] END C=0.1, class_weight=None, gamma=scale, kernel=sigmoid; accuracy: (test=0.512) f1: (test=0.678) precision: (test=0.512) recall: (test=1.000) total time=   0.1s\n",
            "[CV 1/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=  15.3s\n",
            "[CV 2/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.5s\n",
            "[CV 3/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  17.6s\n",
            "[CV 4/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.925) f1: (test=0.927) precision: (test=0.927) recall: (test=0.927) total time=  20.6s\n",
            "[CV 5/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.963) f1: (test=0.964) precision: (test=0.952) recall: (test=0.976) total time=  20.1s\n",
            "[CV 6/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.938) f1: (test=0.938) precision: (test=0.950) recall: (test=0.927) total time=  21.6s\n",
            "[CV 7/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  16.5s\n",
            "[CV 8/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.988) f1: (test=0.988) precision: (test=0.976) recall: (test=1.000) total time=  19.5s\n",
            "[CV 9/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.963) f1: (test=0.963) precision: (test=0.975) recall: (test=0.951) total time=  16.2s\n",
            "[CV 10/10] END C=0.1, class_weight=None, gamma=auto, kernel=linear; accuracy: (test=0.975) f1: (test=0.975) precision: (test=1.000) recall: (test=0.951) total time=  16.5s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Definisci il modello SVC\n",
        "model = SVC()\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100, 1000],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
        "}\n",
        "\n",
        "precision_scorer = make_scorer(precision_score, zero_division=0)\n",
        "custom_scoring = {\"accuracy\": \"accuracy\", \"precision\": precision_scorer, \"recall\": \"recall\", \"f1\": \"f1\"}\n",
        "\n",
        "grid_svc = GridSearchCV(model, param_grid, refit = 'accuracy', verbose = 3, scoring=custom_scoring, cv=10)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid_svc.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid_svc.best_params_)\n",
        "\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_svc.best_estimator_)\n",
        "\n",
        "grid_svc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJsoU14alg"
      },
      "source": [
        "# RQ1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2PmZ-sL8JQ9"
      },
      "source": [
        "1. trova miglior modello\n",
        "2. traino su dataset artificiale e testo sul dataset reale\n",
        "3. potrebbe avere senso fare test statistico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlPoTtmR3lk0"
      },
      "source": [
        "*Il modello migliore è AdaBoostClassifier.*\n",
        "\n",
        "*Nella seguente cella si va a trainare AdaBoostClassifier sul dataset generato e lo si testa sul dataset reale.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwOPCUox8Xkh"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_path = \"/content/QUALITY/datasets/2-Shot/terzo_dataset_generato.csv\"\n",
        "dataset = pd.read_csv(data_path)\n",
        "categorical_features = ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
        "\n",
        "X = dataset.drop('target', axis=1)\n",
        "y = dataset['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = preprocessor.transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "# Creiamo i nomi delle colonne per le feature trasformate\n",
        "ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "# Creiamo i nomi delle colonne per il DataFrame finale\n",
        "colonne_numeriche = ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute13', 'Attribute16', 'Attribute18']\n",
        "feature_names = list(ohe_feature_names) + colonne_numeriche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV8Tdq6U4ROF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b6e4c7-4aca-46dc-a14d-4fc660b6bfbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape di X_train: (800, 57)\n",
            "Shape di X_test: (200, 57)\n",
            "Accuracy = 0.955\n",
            "F1 score = 0.9508196721311475\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "ada_boost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), \\\n",
        "                                     learning_rate=1.5, n_estimators=200)\n",
        "\n",
        "ada_boost_model.fit(X_train, y_train)\n",
        "print(\"Shape di X_train:\", X_train.shape)\n",
        "print(\"Shape di X_test:\", X_test.shape)\n",
        "\n",
        "\n",
        "y_pred = ada_boost_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy = {accuracy}\")\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 score = {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjapEcPLNXJE"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/QUALITY/datasets/german_dataset.csv\"\n",
        "\n",
        "dataset_originale = pd.read_csv(data_path)\n",
        "\n",
        "X = dataset_originale.drop('target', axis=1)\n",
        "y = dataset_originale['target']\n",
        "\n",
        "X = preprocessor.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHcljuqbNVB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76707216-290e-4c86-ef39-7de1deae2552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.557\n",
            "F1 score = 0.6541764246682279\n"
          ]
        }
      ],
      "source": [
        "# Qui si vedono le performance del modello sul dataset originale\n",
        "y_pred_original_dataset = ada_boost_model.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred_original_dataset)\n",
        "print(f\"Accuracy = {accuracy}\")\n",
        "\n",
        "f1 = f1_score(y, y_pred_original_dataset)\n",
        "print(f\"F1 score = {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSWjZFjNxBlR"
      },
      "source": [
        "# RQ0: somiglianza fra dataset originale e dataset generato sinteticamente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D_gJ0L6axFN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d7716195-6c6b-4f6f-8714-a9263feb035c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/QUALITY/datasets/german_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2ca01206c50b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset_originale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/QUALITY/datasets/german_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdataset_sintetico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/QUALITY/datasets/2-Shot/terzo_dataset_generato.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/QUALITY/datasets/german_dataset.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_originale = pd.read_csv(\"/content/QUALITY/datasets/german_dataset.csv\")\n",
        "dataset_sintetico = pd.read_csv(\"/content/QUALITY/datasets/2-Shot/terzo_dataset_generato.csv\")\n",
        "\n",
        "righe_comuni = pd.merge(dataset_originale, dataset_sintetico, how='inner')\n",
        "\n",
        "print(f\"\\nRighe comuni: \\n{righe_comuni}\\n\")\n",
        "\n",
        "num_righe_comuni = righe_comuni.shape[0]\n",
        "print(f\"\\nNumero di righe uguali tra i due DataFrame: {num_righe_comuni}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nwqzWCv-aJOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c63ef0-9188-45cb-f4db-1b1e6327b969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di righe duplicate: 282\n"
          ]
        }
      ],
      "source": [
        "# Controlliamo il numero di righe duplicate nel dataset\n",
        "\n",
        "duplicate_rows = dataset_sintetico.duplicated()\n",
        "num_duplicates = duplicate_rows.sum()\n",
        "print(f\"Numero di righe duplicate: {num_duplicates}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDb83xryEe8"
      },
      "source": [
        "## Plot dei dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "45EsyuhiyGzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "4dfb1ef0-0816-4a77-e26d-7670db92b0bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(dataset_originale['Attribute13'], bins=10, kde=True)\n",
        "plt.title('Age Distribution - Original Dataset')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(dataset_sintetico['Attribute13'], bins=10, kde=True)\n",
        "plt.title('Age Distribution - ChatGPT Dataset')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tJg_hG-Jzoyt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "32b4e07a-b3ee-4416-f2a7-89cdd4d0eebf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(dataset_originale['Attribute9'], bins=10, kde=True)\n",
        "plt.title('Sex Distribution - Original Dataset')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(dataset_sintetico['Attribute9'], bins=10, kde=True)\n",
        "plt.title('Sex Distribution - ChatGPT Dataset')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qXmgTOam3sE1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "437cf05c-64ad-4e41-be90-532c8ba6a383"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are all the values for Purpose (Attribute4) in CHATGPT dataset: ['A40' 'A41' 'A49' 'A42' 'A43' 'A44' 'A45' 'A46']\n",
            "These are all the values for Purpose (Attribute4) in the Original dataset: ['A43' 'A46' 'A42' 'A40' 'A41' 'A49' 'A44' 'A45' 'A410' 'A48']\n"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(24, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(x='Attribute4', data=dataset_originale, order=dataset_originale['Attribute4'].value_counts().index, palette=\"viridis\")\n",
        "plt.title('Purpose of Loan Distribution - Original dataset')\n",
        "plt.xlabel('Purpose')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(x='Attribute4', data=dataset_sintetico, order=dataset_sintetico['Attribute4'].value_counts().index, palette=\"viridis\")\n",
        "plt.title('Purpose of Loan Distribution - ChatGPT dataset')\n",
        "plt.xlabel('Purpose')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"These are all the values for Purpose (Attribute4) in CHATGPT dataset: {dataset_sintetico['Attribute4'].unique()}\")\n",
        "print(f\"These are all the values for Purpose (Attribute4) in the Original dataset: {dataset_originale['Attribute4'].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNvONM4wIBF"
      },
      "source": [
        "# Proviamo a rimuovere tutti i duplicati dal dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dcor-etcwEUr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data_path = \"/content/QUALITY/datasets/2-Shot/terzo_dataset_generato.csv\"\n",
        "dataset = pd.read_csv(data_path)\n",
        "dataset = dataset.drop_duplicates()\n",
        "\n",
        "X = dataset.drop('target', axis=1)\n",
        "y = dataset['target']\n",
        "\n",
        "X_train_no_dup, X_test_no_dup, y_train_no_dup, y_test_no_dup = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_no_dup = preprocessor.transform(X_train_no_dup)\n",
        "X_test_no_dup = preprocessor.transform(X_test_no_dup)\n",
        "\n",
        "print(\"Shape di X_train:\", X_train_no_dup.shape)\n",
        "print(\"Shape di X_test:\", X_test_no_dup.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OykXt3FawZVM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "ada_boost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), \\\n",
        "                                     learning_rate=1.5, n_estimators=200)\n",
        "\n",
        "ada_boost_model.fit(X_train_no_dup, y_train_no_dup)\n",
        "\n",
        "y_pred_no_dup = ada_boost_model.predict(X_test_no_dup)\n",
        "accuracy = accuracy_score(y_test_no_dup, y_pred_no_dup)\n",
        "print(f\"Accuracy = {accuracy}\")\n",
        "\n",
        "f1 = f1_score(y_test_no_dup, y_pred_no_dup)\n",
        "print(f\"F1 score = {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsM1j1HewhZW"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/QUALITY/datasets/german_dataset.csv\"  # original dataset\n",
        "dataset = pd.read_csv(data_path)\n",
        "\n",
        "X = dataset.drop('target', axis=1)\n",
        "y = dataset['target']\n",
        "\n",
        "X = preprocessor.transform(X)\n",
        "\n",
        "print(\"Shape di X originale:\", X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ucB5JPIwjVh"
      },
      "outputs": [],
      "source": [
        "# Qui si vedono le performance del modello sul dataset originale\n",
        "y_pred_original_dataset = ada_boost_model.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred_original_dataset)\n",
        "print(f\"Accuracy = {accuracy}\")\n",
        "\n",
        "f1 = f1_score(y, y_pred_original_dataset)\n",
        "print(f\"F1 score = {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbT7-Z6b4rK_"
      },
      "source": [
        "# RQ2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxRkVOEHKnlF"
      },
      "outputs": [],
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import StandardDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "\"\"\"\n",
        "- Sex, privileged: Male, unprivileged: Female   | Attribute9\n",
        "- Age, privileged: Old, unprivileged: Young     | Attribute13\n",
        "\n",
        "Attribute 9:  (qualitative)\n",
        "\t      Personal status and sex\n",
        "\t      A91 : male   : divorced/separated\n",
        "\t      A92 : female : divorced/separated/married\n",
        "        A93 : male   : single\n",
        "\t      A94 : male   : married/widowed\n",
        "\t      A95 : female : single\n",
        "\"\"\"\n",
        "\n",
        "sex_features = ['Attribute9_A91','Attribute9_A92','Attribute9_A93','Attribute9_A94','Attribute9_A95'] # attributi protetti\n",
        "\n",
        "fairness_dataset = pd.DataFrame(X_test.copy(), columns=feature_names)\n",
        "fairness_dataset['target'] = y_test.to_numpy() # and join the target feature with the others\n",
        "\n",
        "predictions = fairness_dataset\n",
        "predictions['target'] = y_pred # but this time the target feature is made by the predictions of our model\n",
        "\n",
        "# This is the object made of the original dataset\n",
        "aif_sex_dataset = BinaryLabelDataset( # Base class for all structured datasets with binary labels.\n",
        "        df=fairness_dataset,\n",
        "        favorable_label=2.0, # This means that a prediction is biased toward the privileged attribute if its value is 2 (True)\n",
        "        unfavorable_label=1.0,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=sex_features,\n",
        "        privileged_protected_attributes=['Attribute9_A91', 'Attribute9_A93', 'Attribute9_A94'] # here we tell AIF that we want to check for predictions that somehow privilege the attribute \"sex_Male\"\n",
        ")\n",
        "\n",
        "# We do the same thing but with the predictions dataset\n",
        "aif_sex_pred = BinaryLabelDataset(\n",
        "        df=predictions,\n",
        "        favorable_label=2.0, # This means that a prediction is biased toward the privileged attribute if its value is 2 (True)\n",
        "        unfavorable_label=1.0,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=sex_features,\n",
        "        privileged_protected_attributes=['Attribute9_A91', 'Attribute9_A93', 'Attribute9_A94'] # here we tell AIF that we want to check for predictions that somehow privilege the attribute \"sex_Male\"\n",
        ")\n",
        "\n",
        "\n",
        "sex_privileged_group = [{'Attribute9_A91':1.0,\n",
        "                         'Attribute9_A92':0.0,\n",
        "                         'Attribute9_A95':0.0,\n",
        "                         },\n",
        "                        {'Attribute9_A93':1.0,\n",
        "                         'Attribute9_A92':0.0,\n",
        "                         'Attribute9_A95':0.0,\n",
        "                         },\n",
        "                        {'Attribute9_A94':1.0,\n",
        "                         'Attribute9_A92':0.0,\n",
        "                         'Attribute9_A95':0.0,\n",
        "                         },\n",
        "                        ] # The privileged group is made of males\n",
        "\n",
        "sex_unprivileged_group = [{'Attribute9_A92':1.0,\n",
        "                         'Attribute9_A91':0.0,\n",
        "                         'Attribute9_A93':0.0,\n",
        "                         'Attribute9_A94':0.0,\n",
        "                         },\n",
        "                        {'Attribute9_A95':1.0,\n",
        "                         'Attribute9_A91':0.0,\n",
        "                         'Attribute9_A93':0.0,\n",
        "                         'Attribute9_A94':0.0,\n",
        "                         }] # The unprivileged group is made of females\n",
        "\n",
        "# We provide the ClassificationMetric object with all the information needed:\n",
        "# aif_sex_dataset - The original test set\n",
        "# aif_sex_pred - A dataset containing the predictions of the model\n",
        "# sex_privileged_group - The privileged group\n",
        "# sex_unprivileged_group - The unprivileged group\n",
        "fairness_metrics = ClassificationMetric(dataset=aif_sex_dataset,\n",
        "                               classified_dataset=aif_sex_pred,\n",
        "                               unprivileged_groups=sex_unprivileged_group,\n",
        "                               privileged_groups=sex_privileged_group)\n",
        "\n",
        "# Values less than 0 indicate that privileged group has higher\n",
        "# proportion of predicted positive outcomes than unprivileged group.\n",
        "# Value higher than 0 indicates that unprivileged group has higher proportion\n",
        "# of predicted positive outcomes than privileged group.\n",
        "SPD = round(fairness_metrics.statistical_parity_difference(),3)\n",
        "\n",
        "# Measures the deviation from the equality of opportunity, which means that the same\n",
        "# proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
        "EOD = round(fairness_metrics.equal_opportunity_difference(),3)\n",
        "\n",
        "# Average of difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
        "# A value of 0 indicates equality of odds, which means that samples in both the privileged and unprivileged\n",
        "# groups have the same probability of being classified positively.\n",
        "AOD = round(fairness_metrics.average_odds_difference(),3)\n",
        "\n",
        "print(f\"Statistical Parity Difference (SPD): {SPD}.  The ideal value of this metric is 0\") # The ideal value of this metric is 0\n",
        "print(f\"Equal Opportunity Difference (EOD): {EOD}. The ideal value is 0.\")\n",
        "print(f\"Average Odds Difference (AOD): {AOD}. The ideal value of this metric is 0.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11rR1aujSczW"
      },
      "outputs": [],
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'y_pred' contains the model predictions\n",
        "# Ensure 'df' has been defined earlier in your script\n",
        "\n",
        "\"\"\"\n",
        "- Age, privileged: Old (>= 30), unprivileged: Young (< 30) | Attribute13\n",
        "\n",
        "Attribute 13: Continuous values for age\n",
        "\"\"\"\n",
        "\n",
        "# Create a binary column for age\n",
        "df['Age_Old'] = np.where(df['Attribute13'] >= 30, 1, 0)\n",
        "df['Age_Young'] = np.where(df['Attribute13'] < 30, 1, 0)\n",
        "\n",
        "categorical_features = ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
        "\n",
        "X = df.drop(['target', 'Attribute13'], axis=1)  # Drop original age column\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', one_hot_encoder, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # Leave other columns untouched\n",
        ")\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Create column names for the transformed features\n",
        "ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "numeric_features = ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute16', 'Attribute18', 'Age_Old', 'Age_Young']\n",
        "feature_names = list(ohe_feature_names) + numeric_features\n",
        "\n",
        "age_features = ['Age_Old', 'Age_Young']  # protected attributes for age\n",
        "\n",
        "# Create DataFrame for fairness evaluation\n",
        "fairness_dataset = pd.DataFrame(X_test.copy(), columns=feature_names)\n",
        "fairness_dataset['target'] = y_test.to_numpy()  # join the target feature with the others\n",
        "\n",
        "predictions = fairness_dataset.copy()\n",
        "predictions['target'] = y_pred  # the target feature is made by the predictions of our model\n",
        "\n",
        "# Create BinaryLabelDataset for the original dataset\n",
        "aif_age_dataset = BinaryLabelDataset(\n",
        "        df=fairness_dataset,\n",
        "        favorable_label=2.0,  # biased towards the privileged attribute if value is 2 (True)\n",
        "        unfavorable_label=1.0,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=age_features,\n",
        "        privileged_protected_attributes=[{'Age_Old': 1.0}]  # privileged: old\n",
        ")\n",
        "\n",
        "# Create BinaryLabelDataset for the predictions\n",
        "aif_age_pred = BinaryLabelDataset(\n",
        "        df=predictions,\n",
        "        favorable_label=2.0,\n",
        "        unfavorable_label=1.0,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=age_features,\n",
        "        privileged_protected_attributes=[{'Age_Old': 1.0}]  # privileged: old\n",
        ")\n",
        "\n",
        "# Define privileged and unprivileged groups\n",
        "age_privileged_group = [{'Age_Old': 1.0}]\n",
        "age_unprivileged_group = [{'Age_Young': 1.0}]\n",
        "\n",
        "# Compute fairness metrics\n",
        "fairness_metrics = ClassificationMetric(dataset=aif_age_dataset,\n",
        "                                        classified_dataset=aif_age_pred,\n",
        "                                        unprivileged_groups=age_unprivileged_group,\n",
        "                                        privileged_groups=age_privileged_group)\n",
        "\n",
        "# Values less than 0 indicate that the privileged group has a higher\n",
        "# proportion of predicted positive outcomes than the unprivileged group.\n",
        "# Values higher than 0 indicate that the unprivileged group has a higher\n",
        "# proportion of predicted positive outcomes than the privileged group.\n",
        "SPD = round(fairness_metrics.statistical_parity_difference(), 3)\n",
        "\n",
        "# Measures the deviation from equality of opportunity, meaning that the same\n",
        "# proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
        "EOD = round(fairness_metrics.equal_opportunity_difference(), 3)\n",
        "\n",
        "# Average of the difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
        "# A value of 0 indicates equality of odds, meaning that samples in both the privileged and unprivileged\n",
        "# groups have the same probability of being classified positively.\n",
        "AOD = round(fairness_metrics.average_odds_difference(), 3)\n",
        "\n",
        "print(f\"Statistical Parity Difference (SPD): {SPD}. The ideal value of this metric is 0\")  # The ideal value of this metric is 0\n",
        "print(f\"Equal Opportunity Difference (EOD): {EOD}. The ideal value is 0.\")\n",
        "print(f\"Average Odds Difference (AOD): {AOD}. The ideal value of this metric is 0.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}